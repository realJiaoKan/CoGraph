{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install SPARQLWrapper networkx pyvis\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from collections import deque\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "SPARQL_ENDPOINT = \"https://sparql.dblp.org/sparql\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_person_uri = \"https://dblp.org/pid/82/7468\"\n",
    "max_depth = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_uri(uri: str) -> str:\n",
    "    \"\"\"\n",
    "    将URI中的非字母数字字符用'_'替换。\n",
    "    并加上前缀'n_'以确保ID不以数字开头。\n",
    "    \"\"\"\n",
    "    # 将所有非字母数字的字符替换成下划线\n",
    "    safe_id = re.sub(r\"[^a-zA-Z0-9]+\", \"_\", uri)\n",
    "    # 以 n_ 做前缀，确保它符合Graphviz对标识符的要求\n",
    "    safe_id = f\"n_{safe_id}\"\n",
    "    return safe_id\n",
    "\n",
    "\n",
    "def sanitize_nodes_and_edges(nodes, edges):\n",
    "    \"\"\"\n",
    "    将原本以URI为key的节点和边，转换成以“安全ID”为key的结构。\n",
    "    返回 (safe_nodes, safe_edges, uri_mapping) 三个值：\n",
    "\n",
    "    - safe_nodes: dict\n",
    "        key = 安全ID(仅包含字母数字和下划线)，\n",
    "        value = { \"label\": 原先的显示名称, \"original_uri\": 原URI 等 }\n",
    "    - safe_edges: dict\n",
    "        key = (安全ID1, 安全ID2) (确保无向图中小的ID在前),\n",
    "        value = { \"weight\": ..., ... }\n",
    "    - uri_mapping: dict\n",
    "        key = 原URI, value = 安全ID (供您在其他地方可能需要反查)\n",
    "    \"\"\"\n",
    "    safe_nodes = {}\n",
    "    safe_edges = {}\n",
    "    uri_mapping = {}\n",
    "\n",
    "    # 1. 为每个节点分配安全ID\n",
    "    for old_uri, info in nodes.items():\n",
    "        new_id = sanitize_uri(old_uri)\n",
    "        uri_mapping[old_uri] = new_id\n",
    "\n",
    "        # 将 name 作为可视化的 label，也可保留更多元数据\n",
    "        safe_nodes[new_id] = {\"name\": info[\"name\"], \"original_uri\": old_uri}\n",
    "\n",
    "    # 2. 处理边，对 (uri1, uri2) 做同样的映射\n",
    "    for (uri1, uri2), einfo in edges.items():\n",
    "        weight = einfo.get(\"weight\", 1)\n",
    "\n",
    "        safe_u1 = uri_mapping[uri1]\n",
    "        safe_u2 = uri_mapping[uri2]\n",
    "\n",
    "        # 确保无向图key有固定顺序(小的ID放前面)\n",
    "        # 防止 (u1, u2) 和 (u2, u1) 重复\n",
    "        if safe_u1 < safe_u2:\n",
    "            edge_key = (safe_u1, safe_u2)\n",
    "        else:\n",
    "            edge_key = (safe_u2, safe_u1)\n",
    "\n",
    "        if edge_key not in safe_edges:\n",
    "            safe_edges[edge_key] = {\"weight\": weight}\n",
    "        else:\n",
    "            # 如果该对已经存在, 累加或别的逻辑(按您需求)\n",
    "            safe_edges[edge_key][\"weight\"] += weight\n",
    "\n",
    "    return safe_nodes, safe_edges, uri_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_person_name(person_uri: str) -> str:\n",
    "    \"\"\"\n",
    "    查询给定 person_uri 的 dblp:creatorName。\n",
    "    如果查询不到，则使用 URI 的最后一段做后备。\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(SPARQL_ENDPOINT)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    PREFIX dblp: <https://dblp.org/rdf/schema#>\n",
    "    SELECT ?name\n",
    "    WHERE {{\n",
    "        OPTIONAL {{ <{person_uri}> dblp:creatorName ?name . }}\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    sparql.setQuery(query)\n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "        bindings = results[\"results\"][\"bindings\"]\n",
    "        if bindings:\n",
    "            # 如果有name就返回\n",
    "            name = bindings[0].get(\"name\", {}).get(\"value\")\n",
    "            if name:\n",
    "                return name\n",
    "        # 若没拿到，则降级到URI后缀\n",
    "        return \"Unknown\"\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] SPARQL query failed when fetching name for {person_uri}: {e}\")\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zied Bouyahia'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Debug]\n",
    "get_person_name(\"https://dblp.org/pid/82/7468\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coauthor_info(person_uri):\n",
    "    \"\"\"\n",
    "    查询给定作者(person_uri)的所有合作者，以及他们的合作文章数量。\n",
    "\n",
    "    返回: List[ (coauthor_uri, coauthor_name, pub_count) ]\n",
    "    - coauthor_uri   : 合作者的URI\n",
    "    - coauthor_name  : 合作者的名字(若无则为空)\n",
    "    - pub_count      : 与 person_uri 之间的合作文章数\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(SPARQL_ENDPOINT)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    # 查询思路:\n",
    "    #   1. 找出 person_uri 的所有论文(?pub)\n",
    "    #   2. 同时也是由 ?coauthor 撰写的论文\n",
    "    #   3. 按 ?coauthor 分组，计算论文总数\n",
    "    #   4. 过滤自己(不包括 person_uri 本人)\n",
    "    query = f\"\"\"\n",
    "    PREFIX dblp: <https://dblp.org/rdf/schema#>\n",
    "\n",
    "    SELECT ?coauthor (SAMPLE(?coauthorName) AS ?name) (COUNT(DISTINCT ?pub) AS ?pubCount)\n",
    "    WHERE {{\n",
    "        ?pub dblp:authoredBy <{person_uri}> ;\n",
    "             dblp:authoredBy ?coauthor .\n",
    "        FILTER (?coauthor != <{person_uri}>)\n",
    "\n",
    "        OPTIONAL {{ ?coauthor dblp:creatorName ?coauthorName . }}\n",
    "    }}\n",
    "    GROUP BY ?coauthor\n",
    "    \"\"\"\n",
    "\n",
    "    sparql.setQuery(query)\n",
    "\n",
    "    try:\n",
    "        results = sparql.query().convert()\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] SPARQL query failed for {person_uri}: {e}\")\n",
    "        return []\n",
    "\n",
    "    coauthors = []\n",
    "    for row in results[\"results\"][\"bindings\"]:\n",
    "        co_uri = row[\"coauthor\"][\"value\"]\n",
    "        co_name = row[\"name\"][\"value\"] if \"name\" in row else \"\"\n",
    "        pub_count = int(row[\"pubCount\"][\"value\"]) if \"pubCount\" in row else 0\n",
    "        coauthors.append((co_uri, co_name, pub_count))\n",
    "\n",
    "    return coauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://dblp.org/pid/03/6572', 'Hedi Haddad', 12),\n",
       " ('https://dblp.org/pid/05/5769', 'Ahmed Nait-Sidi-Moh', 1),\n",
       " ('https://dblp.org/pid/08/565', 'Khaled Ghédira', 4),\n",
       " ('https://dblp.org/pid/17/848', 'Nafaâ Jabeur', 9),\n",
       " ('https://dblp.org/pid/184/9350', 'Leila Horchani', 2),\n",
       " ('https://dblp.org/pid/206/1503', 'Hana Gharrad', 1),\n",
       " ('https://dblp.org/pid/246/1303', 'Shafique A. Chaudhry', 1),\n",
       " ('https://dblp.org/pid/349/4118', 'Mahmoud Mastouri', 1),\n",
       " ('https://dblp.org/pid/70/7470', 'Monia Bellalouna', 4),\n",
       " ('https://dblp.org/pid/76/6334', 'Stéphane Derrode', 5),\n",
       " ('https://dblp.org/pid/81/3284', 'Wojciech Pieczynski', 4),\n",
       " ('https://dblp.org/pid/82/2493', 'Ansar Yasar', 2),\n",
       " ('https://dblp.org/pid/88/7260', 'Patrick Jaillet', 2),\n",
       " ('https://dblp.org/pid/88/7651', 'Fatma Outay', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Debug]\n",
    "get_coauthor_info(\"https://dblp.org/pid/82/7468\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_coauthor_network(root_person_uri, max_depth=1):\n",
    "    \"\"\"\n",
    "    构建合作者网络，使用 BFS 遍历，可指定最大深度 max_depth。\n",
    "\n",
    "    返回:\n",
    "      nodes: dict,\n",
    "        key = 作者URI,\n",
    "        value = {\"name\": 作者姓名(或URI后缀)}\n",
    "      edges: dict,\n",
    "        key = (uri1, uri2) 排序元组(保证无向一致)\n",
    "        value = {\"weight\": 合作次数}\n",
    "    \"\"\"\n",
    "    nodes = {}\n",
    "    edges = {}\n",
    "\n",
    "    queue = deque()\n",
    "    visited = set()\n",
    "\n",
    "    # 初始化队列\n",
    "    queue.append((root_person_uri, 0))\n",
    "    visited.add(root_person_uri)\n",
    "\n",
    "    # 我们也可以先为root节点获取一个名字(可写成一个函数), 这里简单处理:\n",
    "    root_name = get_person_name(root_person_uri)\n",
    "    nodes[root_person_uri] = {\"name\": root_name}\n",
    "\n",
    "    while queue:\n",
    "        current_person, depth = queue.popleft()\n",
    "\n",
    "        # 日志输出：告诉我们正在处理谁，以及深度\n",
    "        # print(f\"[INFO] Depth={depth}: Processing author {current_person} ...\")\n",
    "\n",
    "        if depth >= max_depth:\n",
    "            # 达到或超过最大深度，不再向下搜索\n",
    "            continue\n",
    "\n",
    "        # 获取当前作者的所有合作者信息\n",
    "        coauthors = get_coauthor_info(current_person)\n",
    "        # print(f\"       Found {len(coauthors)} coauthors for {current_person}.\")\n",
    "\n",
    "        for co_uri, co_name, pub_count in coauthors:\n",
    "            # 如果还没在节点里，记录下名字\n",
    "            if co_uri not in nodes:\n",
    "                nodes[co_uri] = {\"name\": co_name if co_name else \"Unknown\"}\n",
    "\n",
    "            # 构造无向边的key(排序后存储)\n",
    "            edge_key = tuple(sorted([current_person, co_uri]))\n",
    "\n",
    "            if edge_key not in edges:\n",
    "                edges[edge_key] = {\"weight\": pub_count}\n",
    "            else:\n",
    "                # 如果已经有了边，则将合作次数累加或取最大值，视需求而定\n",
    "                # 这里以累加为例:\n",
    "                # edges[edge_key][\"weight\"] += pub_count\n",
    "                pass\n",
    "\n",
    "            # BFS入队处理\n",
    "            if co_uri not in visited:\n",
    "                visited.add(co_uri)\n",
    "                queue.append((co_uri, depth + 1))\n",
    "\n",
    "    nodes, edges, _ = sanitize_nodes_and_edges(nodes, edges)\n",
    "\n",
    "    return nodes, edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adjacency_list(nodes, edges):\n",
    "    adj_list = {}\n",
    "\n",
    "    for node_uri in nodes:\n",
    "        adj_list[node_uri] = []\n",
    "\n",
    "    for (uri1, uri2), edge_info in edges.items():\n",
    "        weight = edge_info.get(\"weight\", 1)\n",
    "\n",
    "        adj_list[uri1].append((uri2, weight))\n",
    "        adj_list[uri2].append((uri1, weight))\n",
    "\n",
    "    return adj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_https_dblp_org_pid_82_7468': [('n_https_dblp_org_pid_03_6572', 12),\n",
       "  ('n_https_dblp_org_pid_05_5769', 1),\n",
       "  ('n_https_dblp_org_pid_08_565', 4),\n",
       "  ('n_https_dblp_org_pid_17_848', 9),\n",
       "  ('n_https_dblp_org_pid_184_9350', 2),\n",
       "  ('n_https_dblp_org_pid_206_1503', 1),\n",
       "  ('n_https_dblp_org_pid_246_1303', 1),\n",
       "  ('n_https_dblp_org_pid_349_4118', 1),\n",
       "  ('n_https_dblp_org_pid_70_7470', 4),\n",
       "  ('n_https_dblp_org_pid_76_6334', 5),\n",
       "  ('n_https_dblp_org_pid_81_3284', 4),\n",
       "  ('n_https_dblp_org_pid_82_2493', 2),\n",
       "  ('n_https_dblp_org_pid_88_7260', 2),\n",
       "  ('n_https_dblp_org_pid_88_7651', 1)],\n",
       " 'n_https_dblp_org_pid_03_6572': [('n_https_dblp_org_pid_82_7468', 12)],\n",
       " 'n_https_dblp_org_pid_05_5769': [('n_https_dblp_org_pid_82_7468', 1)],\n",
       " 'n_https_dblp_org_pid_08_565': [('n_https_dblp_org_pid_82_7468', 4)],\n",
       " 'n_https_dblp_org_pid_17_848': [('n_https_dblp_org_pid_82_7468', 9)],\n",
       " 'n_https_dblp_org_pid_184_9350': [('n_https_dblp_org_pid_82_7468', 2)],\n",
       " 'n_https_dblp_org_pid_206_1503': [('n_https_dblp_org_pid_82_7468', 1)],\n",
       " 'n_https_dblp_org_pid_246_1303': [('n_https_dblp_org_pid_82_7468', 1)],\n",
       " 'n_https_dblp_org_pid_349_4118': [('n_https_dblp_org_pid_82_7468', 1)],\n",
       " 'n_https_dblp_org_pid_70_7470': [('n_https_dblp_org_pid_82_7468', 4)],\n",
       " 'n_https_dblp_org_pid_76_6334': [('n_https_dblp_org_pid_82_7468', 5)],\n",
       " 'n_https_dblp_org_pid_81_3284': [('n_https_dblp_org_pid_82_7468', 4)],\n",
       " 'n_https_dblp_org_pid_82_2493': [('n_https_dblp_org_pid_82_7468', 2)],\n",
       " 'n_https_dblp_org_pid_88_7260': [('n_https_dblp_org_pid_82_7468', 2)],\n",
       " 'n_https_dblp_org_pid_88_7651': [('n_https_dblp_org_pid_82_7468', 1)]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [Debug]\n",
    "nodes, edges = build_coauthor_network(\"https://dblp.org/pid/82/7468\", max_depth=1)\n",
    "\n",
    "build_adjacency_list(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_interactive_pyvis(\n",
    "    nodes, edges, root_id, output_filename=\"coauthor_network_interactive\"\n",
    "):\n",
    "    G = nx.Graph()\n",
    "    for node_id, info in nodes.items():\n",
    "        if node_id == root_id:\n",
    "            G.add_node(node_id, label=info[\"name\"], color=\"#ED3B3E\", font={\"size\": 24})\n",
    "        else:\n",
    "            G.add_node(node_id, label=info[\"name\"], font={\"size\": 18})\n",
    "    for (u, v), edge_info in edges.items():\n",
    "        G.add_edge(\n",
    "            u,\n",
    "            v,\n",
    "            weight=edge_info[\"weight\"],\n",
    "            label=f\"{edge_info['weight']}\",\n",
    "            font={\"size\": 12},\n",
    "        )\n",
    "\n",
    "    os.makedirs(f\"output/{output_filename}\", exist_ok=True)\n",
    "\n",
    "    net = Network(height=\"100vh\", width=\"100vw\")\n",
    "    net.from_nx(G)\n",
    "    net.save_graph(f\"output/{output_filename}/graph.html\")\n",
    "\n",
    "    with open(f\"output/{output_filename}/graph.pkl\", \"wb\") as f:\n",
    "        pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Debug]\n",
    "visualize_interactive_pyvis(\n",
    "    nodes,\n",
    "    edges,\n",
    "    root_id=sanitize_uri(\"https://dblp.org/pid/82/7468\"),\n",
    "    output_filename=\"coauthor_network_interactive_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Building co-author network for https://dblp.org/pid/82/7468, up to depth=2 ===\n",
      "Total authors found: 759\n",
      "Total edges found: 878\n",
      "[INFO] Done.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\n",
    "        f\"=== Building co-author network for {root_person_uri}, up to depth={max_depth} ===\"\n",
    "    )\n",
    "    nodes, edges = build_coauthor_network(root_person_uri, max_depth=max_depth)\n",
    "\n",
    "    print(f\"Total authors found: {len(nodes)}\")\n",
    "    print(f\"Total edges found: {len(edges)}\")\n",
    "\n",
    "    # 可视化图\n",
    "    visualize_interactive_pyvis(\n",
    "        nodes,\n",
    "        edges,\n",
    "        root_id=sanitize_uri(root_person_uri),\n",
    "        output_filename=f\"Coauthor Network of {get_person_name(root_person_uri)} with Depth {max_depth}\",\n",
    "    )\n",
    "\n",
    "    # 日志：完成\n",
    "    print(\"[INFO] Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
